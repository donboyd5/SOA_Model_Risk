---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Historical facts for investment returns

```{r}
#| label: includes
#| include: false

source(here::here("r", "libraries.r"))
source(here::here("r", "libraries_ts.r"))
source(here::here("r", "constants.r"))
source(here::here("r", "functions.r"))

```

## Characteristics of selected U.S. assets: 1928-2022

Now we examine characteristics of returns from six U.S. asset classes plus the CPI using data compiled by Aswath Damodaran at New York University. For details, see the documentation in the [Appendix](appdx_damodaran_data.qmd). The asset classes are:

-   baacorp - Moody's Aaa and Baa corporate bonds, average

-   cpiu - Consumer Price Index, all urban consumers

-   gold - year-end price

-   realestate - residential, similar to Case-Schiller index

-   sp500 - S&P 500 index total return (including dividends)

-   tbill3 - 3-month Treasury bill, average rate for the year

-   ustbond - 10-year constant maturity Treasury bond

```{r}
#| label: ONETIME-download-data
#| include: false
#| eval: false

# https://pages.stern.nyu.edu/~adamodar/New_Home_Page/home.htm
# https://www.stern.nyu.edu/faculty/bio/aswath-damodaran
# https://pages.stern.nyu.edu/~adamodar/New_Home_Page/data.html
# https://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/histretSP.html
# https://www.stern.nyu.edu/~adamodar/pc/datasets/histretSP.xls

url <- "https://www.stern.nyu.edu/~adamodar/pc/datasets/histretSP.xls"
dest <- here::here("data", fs::path_file(url))
download.file(url, dest, mode="wb")

```

```{r}
#| label: ONETIME-get-save-data
#| include: false
#| eval: false


url <- "https://www.stern.nyu.edu/~adamodar/pc/datasets/histretSP.xls"
fpath <- here::here("data", fs::path_file(url))

df1 <- read_excel(fpath, sheet="Returns by year",
                  range="A18:X113")
glimpse(df1)

dfnames <- tibble(vnum=1:length(names(df1)), vname=names(df1))
dfnames

df2 <- df1 |> 
  select(year=`Year`,
         sp500=2, 
         tbill3=3,
         ustbond=4,
         baacorp=5,
         realestate=6,
         gold=7,
         cpiu=18)

# do some checks on the data to be sure they match what Damodaran has
# here's what he report for 1928-2022 nominal average returns; cpiu calc'd by djb
# for       sp500, tbill3, ustbond, baacorp, realestate, gold; cpiu
# 1928-2022	11.51%  3.32%   4.87%   6.96%      4.42%    6.48%;  3.11%
skim(df2) # good - the numbers match

saveRDS(df2, here::here("data", "damodaran_data.rds"))


```

```{r}
#| label: load-data
#| include: false

returns <- readRDS(here::here("data", "damodaran_data.rds"))
retlong <- returns |> 
  pivot_longer(-year)

# get min, max, mean, sd, kurt for normal curve and other purposes
measures <- retlong |>
  summarise(uvmeasures(value),
            .by=name) |> 
  arrange(name)


```

Here are selected summary statistics for the asset classes.

**Skewness**: A measure of symmetry -- the more positive the skewness statistic, the more the distribution is positively skewed and the tail is longer on the right side. The more negative the statistic, the longer the tail is to the left.

**Excess kurtosis**: A measure of fat-tailedness relative to the normal distribution. The more positive it is, the more fat-tailed it is than the normal distribution.

```{r}
#| label: sumstats
#| include: true

measures |> 
  gt() |> 
   tab_header(
    title = html("Summary measures for selected U.S. asset classes, 1928-2022"),
    subtitle=html("Based on annual returns")
  ) |>
  cols_label(name=html("Asset class"),
             skew = html("Skewness"),
             xkurt = html("Excess kurtosis")) |>
  fmt_number(columns=c(skew, xkurt),
             decimals=3) |> 
  fmt_percent(columns=c(min, max, mean, sd), decimals=1)|>
  tab_source_note(source_note="Data source: Aswath Damodaran, New York University")

```

### Plot each series

```{r}
#| label: plot
#| include: true

p <- retlong |> 
  filter(!name %in% c("cpiu", "gold")) |> 
  ggplot(aes(year, value)) +
  geom_line(colour="blue") +
  geom_hline(yintercept = 0) +
  geom_hline(aes(yintercept=mean), data=measures |> filter(!name %in% c("cpiu", "gold")),
             colour="red") +
  scale_y_continuous(name="% return",
                     breaks=seq(-1, 1, .1),
                     labels = label_percent(accuracy=1)) +
  scale_x_continuous(name=NULL) +
  facet_wrap(~name, ncol=3) +
  theme_bw() +
  ggtitle("Annual investment returns",
          subtitle="Red horizontal line gives mean return")

p

```

### Comparison to normality

#### Individual assets

```{r}
#| label: plot-normal
#| include: true

nobs <- 1000
normal_density <- measures %>%
  reframe(value=seq(min, max, length.out=nobs),
          density = dnorm(seq(min, max, length.out = nobs),
                          mean, sd),
          .by=name)

# Create the faceted plot
p <- retlong |> 
  filter(!name %in% c("cpiu", "gold")) |> 
  ggplot() +
  geom_histogram(aes(x = value, y = after_stat(density)), binwidth = .01, fill = "lightblue", alpha = 0.7) +
  facet_wrap(~ name, ncol = 2, scales="free") +
  geom_line(aes(x = value, y = density, group = name), color = "red", linewidth = 1,
            data = normal_density |> filter(!name %in% c("cpiu", "gold"))) +
  geom_vline(aes(xintercept=mean), data=measures |> filter(!name %in% c("cpiu", "gold"))) +
  scale_x_continuous(labels=label_percent(accuracy=1)) +
  theme_bw() +
  labs(title="Annual investment returns",
       subtitle = "Histograms with normal curve overlay",
       x = "% return",
       y = "density")

p

```

## Auto correlation

Each point is the correlation coefficient between current observations and a particular lag of the observations.

```{r}
#| label: plot-acf
#| eval: true
#| include: true
#| fig-width: 10
#| fig-height: 8

# Convert to tsibble
data_tsibble <- retlong |> 
  filter(!name %in% c("cpiu", "gold")) |> 
  as_tsibble(index = year, key = name)

data_tsibble |> 
  ACF(value, lag_max=10) |> 
  ggplot(aes(x=lag, y=acf)) +
  geom_point(colour="blue") +
  geom_line(colour="blue", size=1.25)  +
  geom_hline(yintercept = 0) +
  geom_hline(yintercept=c(-.2, .2), linetype="dashed") +
  scale_x_continuous(breaks=1:10) +
  facet_wrap(~ name, ncol = 2) +
  theme_bw() +
  ggtitle("Autocorrelation plots of investment returns")

```

## Correlation across asset classes

How to read a correlation plot:

-   Diagonal shows a kernel density curve for each asset class (similar to a normal curve for normally distributed data, but for the actual data for a given investment class).

-   Upper triangle shows correlation coefficent between two asset classes.

-   Lower triangle shows scatterplot for 2 asset classes. To find the scatterplot associated with a given correlation coefficient, look along the southwest diagonal from the correlation, counting the same number of boxes on the lower side of the diagonal as it is on the upper side.

```{r}
#| label: plot-corr
#| eval: false
#| include: false

# in interest of speed, set eval to false -- calc in advance and save plot


# returns
# cor(returns)

# library(GGally)

p <- returns |> 
  select(sort(colnames(returns))) |> 
  select(-year) |> 
  ggpairs(title="Correlation plot")

ggpsave <- function(plot, fpath, pointsize=5, res=72) {
  png(fpath, height=1000, width=1000, units="px", pointsize=pointsize, res=res)
  print(plot)
  dev.off()
}

fpath <- here::here("project_webpage", "history_corrplot.png")
ggpsave(p, fpath, pointsize=10, res=100)

```

![](history_corrplot.png)

## Portfolios

We've constructed 3 stocks-bonds portfolios (sp500-baacorp): 75-25, 50-50, and 25-75.

```{r}
#| label: portfolio-efficient
#| eval: false
#| include: false

# find the efficient portfolio - it takes some time so run in advance and save results

# create an xts object
ret2 <- returns |> 
  filter(year %in% 1950:2022) |> 
  mutate(date=strptime(year, "%Y")) |>
  select(-year, -cpiu)
xret <- as.xts(ret2 |> select(-date), ret2$date)  

# construct the portfolio specification
ps <- portfolio.spec(colnames(xret))
ps <- add.constraint(portfolio =ps, type = "full_investment")
ps <- add.constraint(portfolio = ps, type = "long_only")
ps <- add.objective(portfolio = ps, type = "risk", name = "StdDev")
# ps <- add.objective(portfolio = ps, type = "return", name = "mean")
ps

# find the optimal risk-minimizing portfolio
opt <- optimize.portfolio(xret, portfolio = ps2, optimize_method = "ROI", trace=TRUE)
opt

# calculate the efficient frontier
eff <- extractEfficientFrontier(
  opt,
  match.col = "StdDev",
  n.portfolios = 1001,
  risk_aversion = NULL)

saveRDS(eff, here::here("data", "eff_history.rds"))

```

### Efficient portfolios

Here are selected points on the efficient mean-variance frontier for long-only portfolios.

```{r}
#| label: portfolio-eff-show
#| eval: true
#| include: true

eff <- readRDS(here::here("data", "eff_history.rds"))

effdf <- frontier_tbl(eff)

indexes <- purrr::map_vec(c(.04, .05, .06, .07, .08, .09, .099, .10, .11), iclosest, effdf$mean)

points <- effdf |> 
  filter(obs %in% indexes) |> 
  rename_with(.fn= ~str_remove(.x, "w."), .cols=starts_with("w."))

points |> 
  select(-out, -obs) |> 
  gt() |> 
   tab_header(
    title = html("Selected points on the mean-variance efficient frontier for long-only portfolios"),
    subtitle=html("Based on annual returns")
  ) |>
  tab_spanner(columns = sp500:gold,
              label="Portfolio weights") |>
  cols_label(mean=html("Mean return"),
             sd=html("Standard deviation of return")) |>
  fmt_percent(columns=mean:gold, decimals=1) |>
  tab_source_note(source_note="Data source: Aswath Damodaran, New York University")

```


```{r}
#| label: portfolios
#| eval: true
#| include: true

# portfolio analytics long-only weights targeting 7%
# sp500 tbill3 ustbond baacorp realestate  gold
# 0.157  0.000       0   0.526      0.234 0.083
# 0.155  0.000       0   0.525      0.238 0.082
# 0.939 0            0   0          0     0.061 # for 11.2%
# .735 0 0 .140 .125
# .487 .341 .172

portfolios <- returns |> 
  mutate(stock75bond25= .75 * sp500 + .25 * baacorp,
         stock50bond50= .5 * sp500 + .5 * baacorp,
         stock25bond75= .25 * sp500 + .75 * baacorp,
         # efflong07=.155 * sp500 + .525 * baacorp + .238 * realestate + .082 * gold,
         efflong099= 
           0.487 * sp500 + 
           0.341 * baacorp + 
           0.172 * gold
         ) |> 
  pivot_longer(-year)
  
portmeas <- portfolios |>
  filter(year %in% 1950:2022) |> 
  summarise(uvmeasures(value),
            .by=name) |> 
  mutate(sdret=sd / mean,
         group=ifelse(str_starts(name, "stock") | str_starts(name, "eff"), "port", "asset")) |> 
  arrange(group, name)

portmeas |> 
  select(-group) |> 
  gt() |> 
   tab_header(
    title = html("Summary measures for selected U.S. asset classes and portfolios, 1950-2022"),
    subtitle=html("Based on annual returns")
  ) |>
  cols_label(min=html("Minimum return"),
             max=html("Maximum return"),
             mean=html("Mean return"),
             sd=html("Standard deviation of return"),
             skew = html("Skewness"),
             xkurt = html("Excess kurtosis"),
             sdret=html("Ratio of standard deviation to mean return")) |>
  fmt_number(columns=c(skew, xkurt, sdret),
             decimals=2) |> 
  fmt_percent(columns=c(min, max, mean, sd), decimals=1)|>
  tab_source_note(source_note="Data source: Aswath Damodaran, New York University")


```

## Impact of periodicity on summary measures of investment returns

```{r}
#| label: apple
#| eval: false
#| include: false

aapl  <- tq_get("AAPL", get = "stock.prices", from = " 1990-01-01")


tmp <- aapl |> 
  mutate(days=date - lag(date),
         days2=as.integer(days))
count(tmp, days)
count(tmp, days2)  

aapl2 <- aapl |> 
  arrange(date) |> 
  mutate(days=as.integer(date - lag(date))) |> 
  filter(days==1) |> 
  mutate(name="aapl", value=adjusted / lag(adjusted) - 1) |> 
  filter(row_number() > 1)

aaplmeas <- aapl2 |> 
  summarise(uvmeasures(value), .by=name)

nobs <- 1000
normal_density <- aaplmeas %>%
  reframe(value=seq(min, max, length.out=nobs),
          density = dnorm(seq(min, max, length.out = nobs),
                          mean, sd),
          .by=name)

# Create the faceted plot
p <- aapl2 |> 
  ggplot() +
  geom_histogram(aes(x = value, y = after_stat(density)), binwidth = .01, fill = "lightblue", alpha = 0.7) +
  geom_line(aes(x = value, y = density, group = name), color = "red", linewidth = 1,
            data = normal_density |> filter(!name %in% c("cpiu", "gold"))) +
  geom_vline(aes(xintercept=mean), data=aaplmeas) +
  scale_x_continuous(labels=label_percent(accuracy=1)) +
  theme_bw() +
  labs(title="Annual investment returns",
       subtitle = "Histograms with normal curve overlay",
       x = "% return",
       y = "density")

p

```

```{r}
#| label: ONETIME-stock-prices-data
#| eval: false
#| include: false

sp500  <- tq_get("^GSPC", get = "stock.prices", from = " 1900-01-01") # , from = " 1990-01-01"
skim(sp500)

# tq_index("SP500")


sp500b <- sp500 |> 
  arrange(date) |> 
  mutate(days=as.integer(date - lag(date))) |> 
  mutate(name="sp500", return=(adjusted / lag(adjusted) - 1) / days)

saveRDS(sp500b, here::here("data", "sp500_daily_yahoofinance.rds"))


```

This section examines how data frequency affects key measures of interest. The data are based on daily closing values for the S&P 500 adjusted for splits and dividends, from Yahoo Finance. We've drawn data for 1928 through 2022. We report results below for 1950 through 2022.

```{r}
#| label: stock-prices
#| eval: true
#| include: false

# https://rpubs.com/juliakresky/955405

tq_transmute_fun_options()

# $quantmod "annualReturn" daily, weekly, monthly, quarterly, annual
# $PerformanceAnalytics "Return.annualized" 

sp500 <- readRDS(here::here("data", "sp500_daily_yahoofinance.rds")) |> 
  # filter(days==1) |> 
  filter(year(date) %in% 1928:2022) #|>   filter(year(date) >= 1960)

sp500meas <- sp500 |> 
  summarise(uvmeasures(return), .by=name)

data <- sp500 |> 
  filter(year(date) >= 1950)

daily <- data  |> 
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "daily", 
                 type       = "arithmetic")

weekly <- data  |> 
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "weekly", 
                 type       = "arithmetic")

monthly <- data  |> 
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "monthly", 
                 type       = "arithmetic")

annual <- data  |> 
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "yearly", 
                 type       = "arithmetic")


stack <- bind_rows(
  daily |> mutate(freq="daily", length=252) |> rename(value=3),
  weekly |> mutate(freq="weekly", length=52) |> rename(value=3),
  monthly |> mutate(freq="monthly", length=12) |> rename(value=3),
  annual |> mutate(freq="annual", length=1) |> rename(value=3)
  ) |> ungroup()

skim(stack)


stackmeas <- stack |> 
  # filter(date >= "1982-09-01", date <= "2020-01-01") |> JF Begin time period
  summarise(length=first(length), uvmeasures(value), .by=c(symbol, freq)) |> 
  mutate(annret=(1 + mean)^length - 1,
         sdret=sd / mean) |> 
  arrange(symbol, desc(length))
stackmeas

portmeas

```

Note that:

-   Volatility falls as we move from daily to annual frequency (the ratio of the standard deviation to the mean return falls)

-   Skewness seems little affected by the data frequency

-   Excess kurtosis declines dramatically as we move from daily to annual frequency, and is approximately normal (i.e., close to zero) at annual frequency

```{r}
#| label: stock-prices-table
#| eval: true
#| include: true

stackmeas |> 
  select(freq, n:sdret) |> 
  gt() |> 
   tab_header(
    title = html("Summary measures for S&P 500 total return at different frequencies, 1950-2022"),
    subtitle=html("Based on daily closing values, adjusted for splits and dividends")
  ) |>
  tab_spanner(columns = min:xkurt,
              label=html("Units based on period returns (daily, weekly, monthly, annual)")) |>
  cols_label(freq=html("Frequency"),
             min=html("Minimum return"),
             max=html("Maximum return"),
             mean=html("Mean return"),
             sd=html("Standard deviation of return"),
             skew = html("Skewness"),
             xkurt = html("Excess kurtosis"),
             annret = html("Annualized return"),
             sdret=html("Ratio of standard deviation to mean return")) |>
  fmt_number(columns=c(skew, xkurt, sdret),
             decimals=2) |> 
  fmt_number(columns=c(n),
             decimals=0) |> 
  fmt_percent(columns=c(min, max, mean, sd, annret), decimals=1)|>
  tab_source_note(source_note="Data source: Yahoo Finance")

```

## How does diversification affect summary measures of investment returns?

TO COME.

```{r}
#| label: ONETIME-get-sp500-stocks
#| eval: false
#| include: false

df <- tq_index("SP500")

sp500_stocks <- tq_get(df$symbol,
                      get  = "stock.prices",
                      from = " 1900-01-01")

saveRDS(sp500_stocks, here::here("data", "sp500_stocks_rawdaily.rds"))
glimpse(sp500_stocks)

sp500_stocks_daily <- 
  sp500_stocks |>
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "daily", 
                 type       = "arithmetic") |> 
  ungroup()
saveRDS(sp500_stocks_daily, here::here("data", "sp500_stocks_daily.rds"))

skim(sp500_stocks_daily)


sp500_stocks_annual <- 
  sp500_stocks |>
    group_by(symbol)  |> 
    tq_transmute(select     = adjusted, 
                 mutate_fun = periodReturn, 
                 period     = "yearly", 
                 type       = "arithmetic") |> 
  ungroup()
saveRDS(sp500_stocks_annual, here::here("data", "sp500_stocks_annual.rds"))
  
skim(sp500_stocks_annual)
head(sp500_stocks_annual)


# check out:
# https://www.r-bloggers.com/2017/07/downloading-sp-500-stock-data-from-googlequandl-with-r-command-line-script/
# https://github.com/Robot-Wealth/r-quant-recipes/blob/master/historical-spx-constituents/historical-spx-constituents.Rmd
# https://robotwealth.com/how-to-get-historical-spx-constituents-data-for-free/
# https://github.com/fja05680/sp500  # see csv file of companies
# https://github.com/datasets/s-and-p-500-companies
# https://datahub.io/core/s-and-p-500-companies-financials/r/1.html
# https://www.kaggle.com/code/paytonfisher/s-p-500-analysis-using-r
# https://site.financialmodelingprep.com/developer/docs/historical-sp-500-companies-api/#R
# https://analyzingalpha.com/sp500-historical-components-and-changes
# https://raw.githubusercontent.com/leosmigel/analyzingalpha/master/2019-09-18-sp500-historical-components-and-changes/sp500_history.csv
# https://github.com/datasets/s-and-p-500-companies/blob/main/data/constituents.csv
# https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks?resource=download

library(quantmod)
getSymbols("AAPL",
           from = "2016/12/31",
           to = "2018/12/31",
           periodicity = "monthly")

mult_stocks <- tq_get(c("FB", "AMZN"),
                      get  = "stock.prices",
                      from = "2016-01-01",
                      to   = "2017-01-01",
                      periodicity = "monthly")

```


```{r}
#| label: stock-diversification-prep
#| eval: true
#| include: false

sp500_stocks <- readRDS(here::here("data", "sp500_stocks_annual.rds"))
skim(sp500_stocks)

stocks2 <- sp500_stocks |> 
  filter(month(date)==12) |> 
  mutate(year=year(date)) |> 
  select(symbol, year, return=yearly.returns)

count(stocks2, year)

```


```{r}
#| label: stock-diversification
#| eval: true
#| include: true
#| fig-width: 10
#| fig-height: 8

# how do our measures change as we change the sample size
# here are counts by year -- so let's use 2019-2022
# 57  2018   494
# 58  2019   498
# 59  2020   500
# 60  2021   501
# 61  2022   503


# create an equally-weighted portfolio of 1, 10, ..., 500 stocks each year
# calculate stats each years


f <- function(symbol, return, nfirms, reps){
  nsought <- nfirms
  if(length(symbol) < nsought) nfirms <- length(symbol)
  tibble(symbol, return, nfirms, nsought) |> 
    # note that if nfirms is > what's available in data, this will use what's available
    rep_slice_sample(n = nfirms, reps = reps)
}

f_get_nfirms <- function(nfirms, reps){
  stocks2 |> 
    filter(year %in% 2019:2022) |> 
    reframe(f(symbol, return, nfirms, reps), .by=year) |> 
    select(year, nfirms, nsought, replicate, symbol, return)
}

# df <- f_get_nfirms(nfirms=1000, reps=10)

df2 <- purrr::map(.x=c(1, 10, 50, 100, 250, 1000), .f=f_get_nfirms, reps=100) |> list_rbind()

# get summary measures for each year
  # get their summary measures and give them a sample id
meas <- df2 |>
  summarise(uvmeasures(return), .by=c(year, nfirms, replicate))
meas
ht(meas)
meas |> filter(nfirms==250)


dflong <- meas |> 
  select(year, nfirms, replicate, mean, sd, skew, xkurt) |> 
  pivot_longer(-c(year, nfirms, replicate), names_to = "measure")|> 
  mutate(nfirms=factor(nfirms))

medians <- dflong |> 
  summarise(median=median(value, na.rm=TRUE), .by = c(year, nfirms, measure))

dflong |> 
  filter(year==2022) |> 
  ggplot(aes(nfirms, value)) +
  # geom_point() +
  geom_quasirandom(size=0.75, colour="blue") +
  geom_point(aes(x=nfirms, y=median), data=medians|> filter(year==2022),
             colour="red", size=1.5) +
  geom_hline(yintercept = 0) +
  # scale_x_continuous(breaks=unique(df$sample)) +
  facet_wrap(~measure, scales = "free_y") +
  labs(x="# of firms sampled", y="value of the measure") +
  ggtitle(label="Summary investment-return statistics for each of 100 random samples of firms in the S&P 500",
          subtitle="For different numbers of firms, year=2022. Each blue dot is a sample. Red dot is median across samples.") +
  theme_bw()





# df <- stocks2 |> 
#   filter(year %in% 2019:2022) |> 
#   reframe(f(symbol, return, 10), .by=year)
# 
# 
# df <- stocks2 |> 
#   filter(year %in% 2019:2022) |> 
#   group_by(year) |> 
#   reframe(rep_slice_sample(n = 50, reps = 10))
# 
# 
# 
# fsamps <- function(size){
#   stocks2 |>
#   group_by(year) |> 
#     slice_sample(n=size)
# }
# 
# 
# 
# samps <- stocks2 |>
#   group_by(year) |> 
#     slice_sample(n=100)
# 
# 
# fsamp <- function(n, df, year){
#   df |> 
#     filter(year==!year) |> 
#     slice_sample(n=n) |> 
#     mutate(sample=n) |> 
#     relocate(sample)
# }

# fsamp(10, stocks2)
# 
# df2 <- purrr::map(.x=c(1, 10, 50, 100, 250, nrow(stocks3)), .f=fsamp, df=stocks3) |> list_rbind()
# 
# df2 |> 
#   summarise(uvmeasures(return), .by=sample)
# 
# # get a bunch of samples
# fmeas <- function(id, df, year){
#   # get a set of samples
#   df <- purrr::map(.x=c(1, 10, 50, 100, 250, nrow(df)), .f=fsamp, df=df, year=year) |>
#     list_rbind()
#   
#   # get their summary measures and give them a sample id
#   meas <- df |>
#     summarise(uvmeasures(return), .by=sample) |>
#     mutate(id=!!id, year=!!year) |>
#     relocate(id, year)
#   meas
# }
# 
# # fmeas(1, stocks3)
# 
# # take multiple samples
# df <- purrr::map(1:100, fmeas, stocks2, 2000) |> list_rbind()
# glimpse(df)
# count(df, id)
# count(df, sample)
# 
# dflong <- df |> 
#   select(id, sample, mean, sd, skew, xkurt) |> 
#   pivot_longer(-c(id, sample), names_to = "measure")|> 
#   mutate(sample=factor(sample))
# 
# medians <- dflong |> 
#   summarise(median=median(value, na.rm=TRUE), .by = c(sample, measure))
# 
# dflong |> 
#   ggplot(aes(sample, value)) +
#   # geom_point() +
#   geom_quasirandom(size=0.75, colour="blue") +
#   geom_point(aes(x=sample, y=median), data=medians, colour="red", size=1.5) +
#   geom_hline(yintercept = 0) +
#   # scale_x_continuous(breaks=unique(df$sample)) +
#   facet_wrap(~measure, scales = "free_y") +
#   labs(x="# of firms sampled", y="value of the measure") +
#   ggtitle(label="Summary investment-return statistics for each of 100 random samples of firms in the S&P 500",
#           subtitle="For different numbers of firms, year=2022. Red dot is median across samples.") +
#   theme_bw()
#   


```


## How do summary measures of investment returns change over time?

```{r}
#| label: stock-prices-rolling
#| eval: true
#| include: true
#| fig-width: 10
#| fig-height: 8


#   #| column: screen-inset-shaded

# returns |>
#   mutate(sp500r=zoo::rollapplyr(sp500, width=30, FUN=e1071::kurtosis, type=1,
#                                 align="right", fill=NA)) |> # partial = FALSE
#   ggplot(aes(year, sp500r)) + geom_line()

retroll <- returns |> 
  select(year, sp500) |> 
  mutate(retroll=zoo::rollapplyr(sp500, width=30, FUN=uvmeasures,
                         align="right", fill=NA),
         n=retroll[, 1],
         min=retroll[, 2],
         max=retroll[, 3],
         mean=retroll[, 4],
         sd=retroll[, 5],
         skew=retroll[, 6],
         xkurt=retroll[, 7]) |> 
  select(-retroll) |> 
  pivot_longer(-year, names_to = "measure") |> 
  mutate(name="sp500")

p <- retroll |> 
  filter(measure %in% c("mean", "sd", "skew", "xkurt"), !is.na(value)) |> 
  mutate(measure=factor(
    measure,
    levels=c("mean", "sd", "skew", "xkurt"),
    labels=c("mean", "sd",
             "skew: negative -> frequent small gains & a few large losses",
             "xkurt: positive -> heavier tails than normal distribution"))) |> 
  arrange(measure) |> 
  ggplot(aes(year, value)) +
  geom_line(colour="blue", linewidth=1.25) +
  # geom_point(colour="blue") +
  geom_hline(yintercept = 0) +
  facet_wrap(~measure, scales="free_y",
             ncol=2) +
  scale_x_continuous(breaks=seq(1900, 2100, 5)) +
  ggtitle("30-year rolling measures for annual S&P 500 total returns") +
  theme_bw() +
  labs(x=NULL, y=NULL, caption = "Data source: Aswath Damodaran, New York University") +
  caption_left
p

# skew: negative=frequent small gains and a few large losses

```

## Notes from research

"we find heteroscedasticity, negative skewness (−1.02) and large positive excess kurtosis (3.63) for the monthly S&P 500 returns" ("our data begin in September 1982 and finish in January 2020") @beginComplexEconomicScenario2021

The table below gives measures for our S&P 500 data over the same time period. While the skewness and excess kurtosis values are similar, they are not the same. However, the Begin paper appears to construct separate values for S&P 500 dividends and prices (unadjusted for dividends), whereas our data are adjusted for dividends. We suspect that explains the difference.

```{r}
#| label: stock-prices-jfbegin
#| eval: true
#| include: true

stack |> 
  filter(date >= "1982-09-01", date <= "2020-01-01") |> # JF Begin time period
  summarise(length=first(length), uvmeasures(value), .by=c(symbol, freq)) |> 
  mutate(annret=(1 + mean)^length - 1,
         sdret=sd / mean) |> 
  arrange(symbol, desc(length)) |> 
  select(freq, n:sdret) |> 
  gt() |> 
   tab_header(
    title = html("Summary measures for S&P 500 total return at different frequencies, Sept 1982 - Jan 2020"),
    subtitle=html("Based on daily closing values, adjusted for splits and dividends")
  ) |>
  tab_spanner(columns = min:xkurt,
              label=html("Units based on period returns (daily, weekly, monthly, annual)")) |>
  cols_label(freq=html("Frequency"),
             min=html("Minimum return"),
             max=html("Maximum return"),
             mean=html("Mean return"),
             sd=html("Standard deviation of return"),
             skew = html("Skewness"),
             xkurt = html("Excess kurtosis"),
             annret = html("Annualized return"),
             sdret=html("Ratio of standard deviation to mean return")) |>
  fmt_number(columns=c(skew, xkurt, sdret),
             decimals=2) |> 
  fmt_number(columns=c(n),
             decimals=0) |> 
  fmt_percent(columns=c(min, max, mean, sd, annret), decimals=1)|>
  tab_source_note(source_note="Data source: Yahoo Finance")
  
```
