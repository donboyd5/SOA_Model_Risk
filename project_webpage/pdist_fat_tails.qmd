---
output: html_document
editor_options: 
  chunk_output_type: inline
---

# Generating investment returns from fat-tailed probability distributions

One probability distribution that can generate time-independent fat-tailed returns is the Student's t distribution.

```{r}
#| label: includes
#| include: false

source(here::here("r", "libraries.r"))
source(here::here("r", "libraries_ts.r"))
source(here::here("r", "constants.r"))
source(here::here("r", "functions.r"))

```

The t distribution has a degrees-of-freedom parameter that controls the "fat-tailedness" of the distribution.

## Choosing the degrees of freedom given targets for mean, standard deviation, and excess kurtosis

To determine the degrees of freedom for a t-distribution given the desired mean, standard deviation, and kurtosis, we use the relationship between the degrees of freedom (ν) and the kurtosis (γ2).

For a t-distribution, kurtosis is defined as:

γ2 = (6(ν-2)) / (ν-4), for ν \> 4

First, we need to find the excess kurtosis, which is the difference between the kurtosis of the desired distribution and the kurtosis of a normal distribution, which is 3. Denote the excess kurtosis as γ2_excess:

γ2_excess = γ2 - 3

Now, we use the relationship between the degrees of freedom and excess kurtosis:

γ2_excess = (6(ν-2)) / (ν-4)

Rearranging to solve for ν (degrees of freedom):

ν = (12 + 6γ2_excess + 2γ2_excess\^2) / (3 + γ2_excess)

If, for example, we are solving for the degrees of freedom needed to generate random values from a t distribution with excess kurtosis of 3, we would have:

ν = (12 + 6 \* 3 + 2 \* 3\^2) / (3 + 3)

ν = 8

The relationship between degrees of freedom and kurtosis is only valid when ν \> 4. If the calculated degrees of freedom fall outside this range, we may need to consider alternative distributions or methods to achieve the desired distribution characteristics.

## Calibrating values from the t distribution to hit desired mean and standard deviation while keeping excess kurtosis constant

The t-distribution's mean and standard deviation can be controlled through shifting and scaling. The mean and standard deviation do not affect the degrees of freedom, which determine the kurtosis and overall shape of the distribution.

Casella, George, and Roger L. Berger. *Statistical Inference*. 2nd ed. Australia ; Pacific Grove, CA: Thomson Learning, 2002. <https://mybiostats.files.wordpress.com/2015/03/casella-berger.pdf>.


```{r}
#| label: kurtosis
#| include: false


```

```{r}
#| label: data
#| include: false

set.seed(constants$seed)
#set.seed(1234)

nyears <- 50
nsims <- 1000

ir_mean_target <- constants$ir_mean_target
ir_sd_target <- constants$ir_sd_target

# ir_mean_target <- .07
# ir_sd_target <- .10

# t_random <- rt(nyears * nsims, dfreedom)

set.seed(1234)
ir_mean_target <- .07
ir_sd_target <- .10
dfreedom <- 3

trandom <- rt(nyears * nsims, dfreedom)
mean(trandom)
sd(trandom)
kurt <- kurtosis(trandom)
excess_kurt <- kurt - 3
excess_kurt

# Scale and shift the random numbers to the desired mean and standard deviation
sdadjust <- ir_sd_target / sd(trandom)
muadjust <- (ir_mean_target - sdadjust * mean(trandom)) / sdadjust

ir <- (trandom + muadjust) * sdadjust
# mean(ir)
# sd(ir)
# irkurt <- kurtosis(ir)
# irexcess <- irkurt - 3
# irexcess
# 
# # Run the ks.test comparing the standardized values with the t-distribution
# standardized_ir <- (ir - mean(ir)) / sd(ir)
# ks_result <- ks.test(standardized_ir, "pt", dfreedom)
# 
# # Show the test results
# cat("Kolmogorov-Smirnov test statistic:", ks_result$statistic, "\n")
# cat("p-value:", ks_result$p.value, "\n")
# # If the p-value is greater than a chosen significance level (e.g., 0.05), you can conclude that the adjusted values are not significantly different from the t-distribution. 
# 
# 
# ir <- ir_mean_target + ir_sd_target * t_random
# 
# ir <- ir_mean_target + ir_sd_target * t_random
# mean(ir) # 0.07024717
# sd(ir) # 0.120183
# 
# 
# ir <- ir_mean_target*.998 + ir_sd_target * t_random * .775
# 
# 
# set.seed(1234)
# 
# ir_mean_target <- 0.07
# ir_sd_target <- 0.10
# max_iter <- 1000
# best_diff <- Inf
# best_df <- -1
# best_ir <- NULL
# 
# # Search for the best degrees of freedom
# for (i in 1:max_iter) {
#   dfreedom <- i
#   t_random <- rt(nyears * nsims, dfreedom)
#   ir <- ir_mean_target + ir_sd_target * t_random
#   cur_mean <- mean(ir)
#   cur_sd <- sd(ir)
#   
#   # Calculate the total difference between current and target values
#   diff <- abs(cur_mean - ir_mean_target) + abs(cur_sd - ir_sd_target)
#   
#   if (diff < best_diff) {
#     best_diff <- diff
#     best_df <- dfreedom
#     best_ir <- ir
#     best_t <- t_random
#     
#     # Break the loop if the difference is small enough
#     if (best_diff < 1e-6) {
#       break
#     }
#   }
# }
# 
# # Adjust the scale and shift factors
# actual_mean <- mean(best_ir)
# actual_sd <- sd(best_ir)
# sd_adjustment <- ir_sd_target / actual_sd
# adjusted_ir <- (best_ir - actual_mean) * sd_adjustment + ir_mean_target
# 
# mean(adjusted_ir)
# sd(adjusted_ir)
# 
# 
# standardized_ir <- (adjusted_ir - mean(adjusted_ir)) / sd(adjusted_ir)
# 
# # Run the ks.test comparing the standardized values with the t-distribution
# ks_result <- ks.test(standardized_ir, "pt", best_df)
# 
# # Show the test results
# cat("Kolmogorov-Smirnov test statistic:", ks_result$statistic, "\n")
# cat("p-value:", ks_result$p.value, "\n")
# # If the p-value is greater than a chosen significance level (e.g., 0.05), you can conclude that the adjusted values are not significantly different from the t-distribution. 
# 
# t_adj <- (best_t - mean(best_t)) / sd(best_t)
# tks <- ks.test(t_adj, "pt", best_df)
# tks$p.value

stubs <- crossing(year=1:nyears, sim=1:nsims)

df <- stubs |> 
  mutate(ir=ir)
glimpse(df)
skim(df)

```

```{r}
#| label: hist
#| include: true

title1 <- paste0("Investment returns drawn from the t distribution, calibrated to: mean ",
                 f_pct(mean(ir), accuracy=.1),
                 " and standard deviation ",
                 f_pct(sd(ir), accuracy=.1))

#create histogram and overlay normal curve
p <- df |> 
  ggplot(aes(x=ir)) +
  geom_histogram(aes(y = after_stat(density)), bins=30, fill='lightblue', col='grey90') +
  stat_function(fun = dnorm, args = list(mean=mean(df$ir), sd=sd(df$ir)), col="black") +
  geom_vline(xintercept = mean(ir)) +
  labs(x="investment return", y="density") +
  scale_x_continuous(breaks=c(seq(-10, 10, .2), mean(df$ir)), labels = scales::label_percent(accuracy=.1),
                     limits=c(-.6, .6)) +
  ggtitle(title1,
          subtitle="Overlaid normal curve has same mean and standard deviation") +
  theme_bw()
p

```
